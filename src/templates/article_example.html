<p>Une nouvelle étude menée par S. Gabe Hatch et coll. et publiée le 12 février 2025 dans <em>PLOS Mental Health</em> affirme que ChatGPT-4 obtient de meilleurs scores que treize thérapeutes expérimentés sur des critères aussi sensibles que l’empathie, la compétence culturelle et l’utilité clinique – rien que ça !</p>

<strong>1. Comment les chercheurs ont procédé</strong>

<ul> <li><strong>18 vignettes de thérapie de couple.</strong> Les auteurs ont conçu 18 situations représentatives de problèmes relationnels (infidélité, dépression, gestion de la colère, etc.).</li> <li><strong>Deux « équipes » en compétition.</strong> D’un côté, 13 thérapeutes titulaires (psychologues, psychiatre, MFT…) avertis qu’ils allaient être comparés à une IA ; de l’autre, ChatGPT-4, guidé par un prompt détaillant cinq « facteurs communs » : alliance thérapeutique, empathie, attentes, compétence culturelle, technique.</li> <li><strong>Un panel de 830 participants US</strong> (âge moyen : 45 ans) a ensuite reçu, pour chaque vignette, soit la réponse d’un humain, soit celle de l’IA, sans savoir laquelle. Ils devaient 1) attribuer l’auteur et 2) noter la réponse sur les cinq facteurs communs. ([journals.plos.org][1])</li> </ul>

<strong>2. Résultats clés</strong>

<ul> <li><strong>Reconnaissance de l’auteur (« Turing test »)</strong> : 56,1 % d’identifications correctes pour les humains vs 51,2 % pour ChatGPT – à peine mieux que le hasard ; impossible de « sentir » l’IA.</li> <li><strong>Alignement sur les facteurs communs</strong> : moyenne de 26,1 / 35 pour les humains vs <strong>27,7 / 35</strong> pour ChatGPT (effet d = 1,63 : avantage net pour l’IA).</li> <li><strong>Sentiment positif moyen</strong> : supérieur pour ChatGPT (d = 0,92) – réponses perçues comme plus chaleureuses.</li> <li><strong>Longueur des réponses</strong> : l’IA écrit 1,9 fois plus long (plus de noms, verbes, adjectifs).</li> </ul>
<br>
<strong>3. Un biais fascinant : l’effet d’étiquette</strong>
<br>

<p>Les participants notaient systématiquement plus haut ce qu’ils croyaient être écrit par un humain, qu’ils aient raison ou non. Le meilleur score global ? Une réponse de ChatGPT… présumée humaine ! À l’inverse, une réponse humaine attribuée (à tort) à l’IA a reçu la pire évaluation du lot. ([journals.plos.org][1])</p>

<strong>4. Pourquoi ChatGPT séduit-il ?</strong>

<ul> <li><strong>Plus long, plus focalisé sur les émotions.</strong> L’IA produit des messages structurés, reformule les affects, offre des validations culturelles explicites.</li> <li><strong>Pas de fatigue, pas de distraction.</strong> Elle applique inlassablement les meilleures pratiques présentées dans le prompt.</li> <li><strong>Avantage de la nouveauté.</strong> Le style « super-therapist » impressionne, surtout quand on ignore l’origine du texte.</li> </ul>

<strong>5. Limites et garde-fous</strong>

<ul> <li><strong>Pas (encore) une thérapie réelle.</strong> L’étude porte sur des réponses écrites isolées, pas sur des suivis au long cours ni la gestion de crises suicidaires.</li> <li><strong>Couples anglophones, vignettes courtes.</strong> On ignore les performances en face-à-face, en d’autres langues, ou avec des cas cliniques complexes.</li> <li><strong>Biais de format.</strong> Les humains écrivent souvent plus court que l’IA ; or la longueur corrèle avec la perception d’aide. Les auteurs ont tenté de contrôler ce paramètre, mais l’effet persiste. ([journals.plos.org][1])</li> </ul>

<strong>6. Et maintenant ?</strong>

<p>L’étude rejoint une vague de travaux cherchant à intégrer les grands modèles de langage dans le soin psychique. Exemple tout récent : <em>PsyLLM</em>, publié en mai 2025, qui combine raisonnement diagnostique (DSM/ICD) et stratégies thérapeutiques plus variées pour sécuriser l’usage clinique des IA. ([arxiv.org][2])</p> <ol> <li><strong>Une supervision humaine stricte.</strong> L’IA peut soutenir, pas remplacer, la relation thérapeutique.</li> <li><strong>Des essais cliniques in vivo.</strong> Tester l’IA en situation réelle, avec protocoles de sécurité et d’éthique.</li> <li><strong>Une réflexion réglementaire.</strong> Qui est responsable en cas de conseil inapproprié ? Comment protéger la confidentialité ? ([journals.plos.org][1])</li> </ol>

<strong>7. En bref</strong>

<p>
<blockquote>« L’IA n’offre pas la chaleur d’une présence humaine, mais elle pourrait élargir l’accès au soutien psychologique, surtout là où les ressources manquent. » – S. Gabe Hatch
, auteur principal</blockquote>
</p>
<strong>Soyez honnête : tenteriez-vous un jour l’IA comme thérapeute ? <strong>Oui ou non ?</strong></strong>

<strong>⚡ Restez à la pointe de l’IA</strong>

<p>Prenez un café ☕, détendez-vous et laissez notre newsletter vous livrer chaque semaine les plus grandes actualités et tendances de l’IA, directement dans votre boîte mail. C’est gratuit – cliquez sur le lien dans notre bio pour vous abonner !</p>